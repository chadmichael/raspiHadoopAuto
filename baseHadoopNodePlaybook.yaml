---
- hosts: raspiHadoopCluster
  remote_user: pi
  become: yes
  tasks:
  - name: create users  
    user: 
      name: hadoop 
      comment: hadoop service account
  - name: verify headless openJDK 8 jre
    apt: 
      name: openjdk-8-jre-headless  
      state: present
      
  # We have to remove all the OpenJDK 11 stuff found on the Raspbian base OS    
  - name: verify absense JRE 11
    apt: 
      name: openjdk-11-jre 
      state: absent
  - name: verify absense jre 11 headless
    apt: 
      name: openjdk-11-jre-headless 
      state: absent  
  - name: verify absense jdk 11                  
    apt: 
      name: openjdk-11-jdk 
      state: absent
  - name: verify absense jdk 11 headless
    apt: 
      name: openjdk-11-jdk-headless 
      state: absent                  

 # Hadoop Dependencies
  - name: Verify Rsync
    apt:
      name: rsync
      state: present

  # Apt Cleanup
  - name: remove useless packages from the cache
    apt:
      autoclean: yes
  - name: remove dependencies that are no longer required
    apt:
      autoremove: yes
      
  # Hadoop Install    
  - name: Deploy hadoop binary artifact to nodes 
    unarchive:
      src: /home/chadmichael/Documents/techReference/hadoop/hadoop-2.10.0.tar.gz
      dest: /home/hadoop/hadoop
      creates: yes
      owner: hadoop
      group: hadoop
      mode: u=rw,g=r,o=r
      keep_newer: yes
    
# MASTER 

- hosts: raspiHadoopNameNode
  remote_user: pi
  become: yes
  tasks:
  - name: Verify user local ssh folder
    file:
      path: /home/hadoop/.ssh
      state: directory
      mode: '0755'
      owner: hadoop
      group: hadoop
  - name: Create keys for hadoop user on master node
    openssh_keypair:
      path: /home/hadoop/.ssh/id_rsa
      owner: hadoop
      group: hadoop
    notify: 
        - Save Master Keys
        
  # BUG BUG BUG: on a clean run this will fail because it depends on the keys being saved locally from the data node play below ...
  #- name: Add data node host keys to master node known hosts
  
    ## APPEND TO FILE >>>   
    ## WRITE TO CORRECT LOCATION /etc/ssh/known_hosts
    #blockinfile:
      #block: "{{ lookup('file', 'keys/dataNode/host_key_{{item}}.pub') }}"
      #dest: /home/hadoop/.ssh/known_hosts
      #insertafter: EOF
      #create: true
      #marker_begin: "{{item}}"
      #marker_end: "{{item}}"
      #owner: hadoop
      #group: hadoop  
    #loop: "{{groups['raspiHadoopDataNode']}}"
    
  # NOT IDEMPOTENT ... the known_hosts file keeps growing everytime we run the automation...  
  - name: Add data node host keys to master node known_hosts via keyscan
    shell: ssh-keyscan -H {{item}} >> /home/hadoop/.ssh/known_hosts
    loop: "{{groups['raspiHadoopDataNode']}}"
    
  handlers:
    - name: Save Master Keys
      fetch:
        src: /home/hadoop/.ssh/id_rsa.pub
        dest: keys/nameNode/id_rsa_nameNode_hadoopUser.pub
        flat: yes
      
# Data Nodes

- hosts: raspiHadoopDataNode
  remote_user: pi
  become: yes
  tasks:
  - name: Save Data Node Host Keys
    fetch: 
      src: /etc/ssh/ssh_host_ecdsa_key.pub
      dest: keys/dataNode/host_key_{{inventory_hostname}}.pub
      flat: yes
  - name: Add hadooop@masternode key to hadoop@dataNodeX authorized keys
    blockinfile:
      block: "{{ lookup('file', 'keys/nameNode/id_rsa_nameNode_hadoopUser.pub') }}"
      dest: /home/hadoop/.ssh/authorized_keys
      insertafter: EOF
      create: yes
      owner: hadoop
      group: hadoop
...
